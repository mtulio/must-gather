#!/bin/bash

# Gather Monitoring Metrics and Dashboards.
# - Discovery Grafana dashboards, save and extract metrics name.
# - Gather custom metrics defined on ConfigMap. If it is not in any dashboards.
#
# ConfigMap:
# - GAHTER_MONITORING_START_DATE: unix date syntax. Default: "7 days ago".
# - GATHER_MONITORING_METRICS_NAME: list of additional metrics name to be collected.
#
# To create the ConfigMap:
# $ echo -e 'export GATHER_MONITORING_METRICS_NAME="up"\nexport GAHTER_MONITORING_START_DATE="1 day ago"' > env
# $ oc create configmap must-gather-env -n openshift-monitoring --from-file=env=env
#
# References:
# - Prometheus API: https://prometheus.io/docs/prometheus/latest/querying/api/
# - Grafana API: https://grafana.com/docs/grafana/latest/http_api/dashboard/

BASE_COLLECTION_PATH="/must-gather"
MONITORING_PATH="${BASE_COLLECTION_PATH}/monitoring/"
PROM_PATH="${MONITORING_PATH}/prometheus"
GF_PATH="${MONITORING_PATH}/grafana"

PROM_HOST=$(oc get route prometheus-k8s -n openshift-monitoring -o jsonpath='{.spec.host}{"\n"}')
PROM_URL="https://${PROM_HOST}"

GF_HOST=$(oc get route grafana -n openshift-monitoring -o jsonpath='{.spec.host}{"\n"}')
GF_URL="https://${GF_HOST}"

CURL_OPTIONS="-k -s"

OCP_TOKEN=$(oc whoami -t)
CM_ENV=must-gather-env
NS=openshift-monitoring

# Read Config
if [[ -z "${GATHER_MONITORING_METRICS_NAME}" ]]; then \
    oc get cm ${CM_ENV} -n ${NS} -o jsonpath='{.data.env}' > .env; \
    source .env; \
fi

_START=${GAHTER_MONITORING_START_DATE:-"7 days ago"}
DATE_START=$(date -d "${_START}" +%s)
DATE_END=$(date +%s)
# If the resolution is too low, the API will deny due to 11k limitation
QUERY_STEP="1m"

function prom_query_range() {
    QUERY=$1
    METRIC_FILE=${2:-$(echo ${QUERY} |awk -F'\(' '{print$1}')}

    curl ${CURL_OPTIONS} \
        -H "Authorization: Bearer ${OCP_TOKEN}" \
        --data-urlencode "query=${QUERY}" \
        --data-urlencode "start=${DATE_START}" \
        --data-urlencode "end=${DATE_END}" \
        --data-urlencode "step=${QUERY_STEP}" \
        $PROM_URL/api/v1/query_range > ${PROM_PATH}/metric-${METRIC_FILE}.json
}

function setup() {

    # install small jq binary (required to parser)
    curl -s -o /usr/local/bin/jq \
      http://stedolan.github.io/jq/download/linux64/jq && \
      chmod +x /usr/local/bin/jq

    test -d ${PROM_PATH} || mkdir -p ${PROM_PATH}
    test -d ${GF_PATH} || mkdir -p ${GF_PATH}
}

# Read ConfigMap CM and gather it's metrics.
# This CM should be in openshift-monitoring namespace.
function get_custom_metrics() {

    echo "INFO: Loading custom metrics from ConfigMap ${CM} on Namespace ${NS}"
    if [[ -z "${GATHER_MONITORING_METRICS_NAME}" ]]; then
        echo "> Unable to find env GATHER_MONITORING_METRICS_NAME, ignoring..."
        return
    fi

    echo "#> Metrics will be collected from [$(date -d "@${DATE_START}")] to [$(date -d "@${DATE_END}")] <#"
    for METRIC in $GATHER_MONITORING_METRICS_NAME; do
        echo "INFO: Getting metric range: $METRIC"
        prom_query_range "$METRIC" "$METRIC"
    done
}

# List all metrics from default folder - where OCP store it's dashboards
function gf_get_dashboards() {
    echo "INFO: Getting Dashboards from default Folder"
    curl ${CURL_OPTIONS} \
        -H "Authorization: Bearer ${OCP_TOKEN}" \
        $GF_URL/api/search?folderIds=1 > ${GF_PATH}/dashboards.json
}

# Read all dashboards, on default folder, and extract metrics/expressions defined on.
# Then collect it's metrics from Prometheus API.
function gf_extract_metrics_from_dashboards() {
    jq -r '.[] | .uri +":"+ .uid' ${GF_PATH}/dashboards.json |awk -F'db/' '{print$2}'|awk '{print$1":"$2}' > ${GF_PATH}/dashboards.txt
    while read DASHBOARD; do
        NAME=$(echo $DASHBOARD |awk -F':' '{print$1}')
        DUID=$(echo $DASHBOARD |awk -F':' '{print$2}')

        echo "INFO: Getting Dashboard ${NAME}"
        curl ${CURL_OPTIONS} \
            -H "Authorization: Bearer ${OCP_TOKEN}" \
            $GF_URL/api/dashboards/uid/${DUID} > ${GF_PATH}/dashboard_${NAME}.json

        jq .dashboard.rows[].panels[].targets[].expr ${GF_PATH}/dashboard_${NAME}.json |egrep -o '\((\w+){\)*' |tr -d '({' > ${GF_PATH}/dashboard_${NAME}_metrics.txt
    done < ${GF_PATH}/dashboards.txt

    echo "INFO: Extracting metrics from dashboards"
    sort -u ${GF_PATH}/dashboard_*_metrics.txt > ${GF_PATH}/dashboards_metrics.txt
    while read METRIC; do
        echo "INFO: Getting metric range: $METRIC"
        prom_query_range "$METRIC" "$METRIC"
    done < ${GF_PATH}/dashboards_metrics.txt
}

# Start
setup

# Get metrics custom metrics
get_custom_metrics

# Get Grafana dashboard and it's metrics data points
gf_get_dashboards
gf_extract_metrics_from_dashboards

# force disk flush to ensure that all data gathered is accessible in the copy container
sync
